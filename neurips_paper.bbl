\begin{thebibliography}{12}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Brown-Cohen et~al.(2023)Brown-Cohen, Irving, and Piliouras]{browncohen2023debate}
Jonah Brown-Cohen, Geoffrey Irving, and Georgios Piliouras.
\newblock Scalable ai safety via doubly-efficient debate.
\newblock \emph{arXiv preprint arXiv:2311.14125}, 2023.
\newblock URL \url{https://arxiv.org/abs/2311.14125}.

\bibitem[Handa et~al.(2025)Handa, Tamkin, McCain, Huang, Durmus, Heck, Mueller, Hong, Ritchie, Belonax, Troy, Amodei, Kaplan, Clark, and Ganguli]{handa2025economictasksperformedai}
Kunal Handa, Alex Tamkin, Miles McCain, Saffron Huang, Esin Durmus, Sarah Heck, Jared Mueller, Jerry Hong, Stuart Ritchie, Tim Belonax, Kevin~K. Troy, Dario Amodei, Jared Kaplan, Jack Clark, and Deep Ganguli.
\newblock Which economic tasks are performed with ai? evidence from millions of claude conversations, 2025.
\newblock URL \url{https://arxiv.org/abs/2503.04761}.

\bibitem[Irving et~al.(2018)Irving, Christiano, and Amodei]{irving2018debate}
Geoffrey Irving, Paul Christiano, and Dario Amodei.
\newblock Ai safety via debate.
\newblock \emph{arXiv preprint arXiv:1805.00899}, 2018.
\newblock URL \url{https://arxiv.org/abs/1805.00899}.

\bibitem[Kadavath et~al.(2022)Kadavath, Conerly, Askell, Henighan, Drain, Perez, Schiefer, Hatfield-Dodds, DasSarma, Tran-Johnson, et~al.]{kadavath2022know}
Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, et~al.
\newblock Language models (mostly) know what they know.
\newblock \emph{arXiv preprint arXiv:2207.05221}, 2022.
\newblock URL \url{https://arxiv.org/abs/2207.05221}.

\bibitem[Li et~al.(2024)Li, Chen, Su, Chen, Zhang, Xing, and Zhang]{Li2024ConfidenceMR}
Loka Li, Guan-Hong Chen, Yusheng Su, Zhenhao Chen, Yixuan Zhang, Eric~P. Xing, and Kun Zhang.
\newblock Confidence matters: Revisiting intrinsic self-correction capabilities of large language models.
\newblock \emph{ArXiv}, abs/2402.12563, 2024.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:268032763}.

\bibitem[Rivera et~al.(2023)Rivera, Ye, Kim, and Li]{rivera2023assertive}
Colin Rivera, Xinyi Ye, Yonsei Kim, and Wenpeng Li.
\newblock Linguistic assertiveness affects factuality ratings and model behavior in qa systems.
\newblock In \emph{Findings of the Association for Computational Linguistics (ACL)}, 2023.
\newblock URL \url{https://arxiv.org/abs/2305.04745}.

\bibitem[Song et~al.(2025)Song, Hu, and Mahowald]{song2025introspect}
Siyuan Song, Jennifer Hu, and Kyle Mahowald.
\newblock Language models fail to introspect about their knowledge of language.
\newblock \emph{arXiv preprint arXiv:2503.07513}, 2025.
\newblock URL \url{https://arxiv.org/abs/2503.07513}.

\bibitem[Tian et~al.(2023)Tian, Mitchell, Zhou, Sharma, Rafailov, Yao, Finn, and Manning]{tian2023justask}
Katherine Tian, Eric Mitchell, Allan Zhou, Archit Sharma, Rafael Rafailov, Huaxiu Yao, Chelsea Finn, and Christopher~D. Manning.
\newblock Just ask for calibration: Strategies for eliciting calibrated confidence scores from language models fine-tuned with human feedback.
\newblock In \emph{Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP)}, 2023.
\newblock URL \url{https://arxiv.org/abs/2305.14975}.

\bibitem[Xiong et~al.(2024)Xiong, Hu, Lu, Li, Fu, He, and Hooi]{xiong2024uncertainty}
Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu, Junxian He, and Bryan Hooi.
\newblock Can llms express their uncertainty? an empirical evaluation of confidence elicitation in llms.
\newblock In \emph{Proceedings of the 2024 International Conference on Learning Representations (ICLR)}, 2024.
\newblock URL \url{https://arxiv.org/abs/2306.13063}.

\bibitem[Xu et~al.(2023)Xu, Lin, Qiu, et~al.]{xu2023earthflat}
Rongwu Xu, Brian~S. Lin, Han Qiu, et~al.
\newblock The earth is flat because...: Investigating llms' belief towards misinformation via persuasive conversation.
\newblock \emph{arXiv preprint arXiv:2312.06717}, 2023.
\newblock URL \url{https://arxiv.org/abs/2312.06717}.

\bibitem[Zheng et~al.(2025)Zheng, Fu, Hu, Cai, Ye, Lu, and Liu]{zheng2025deepresearcherscalingdeepresearch}
Yuxiang Zheng, Dayuan Fu, Xiangkun Hu, Xiaojie Cai, Lyumanshan Ye, Pengrui Lu, and Pengfei Liu.
\newblock Deepresearcher: Scaling deep research via reinforcement learning in real-world environments, 2025.
\newblock URL \url{https://arxiv.org/abs/2504.03160}.

\bibitem[Zhou et~al.(2023)Zhou, Jurafsky, and Hashimoto]{zhou2023epistemic}
Kaitlyn Zhou, Dan Jurafsky, and Tatsunori Hashimoto.
\newblock Navigating the grey area: How expressions of uncertainty and overconfidence affect language models.
\newblock In \emph{Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP)}, 2023.
\newblock URL \url{https://arxiv.org/abs/2302.13439}.

\end{thebibliography}
